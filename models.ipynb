{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiated\n",
      "printing data shape (548, 16000)\n",
      "0.23636363636363636\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os, numpy\n",
    "import cv2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class model:\n",
    "    def __init__(self):\n",
    "        print (\"initiated\")\n",
    "\n",
    "    def preprocess_data(self,path):\n",
    "        files = os.listdir(path)\n",
    "        orb = cv2.ORB_create()\n",
    "        #sift = cv2.xfeatures2d.SIFT_create()\n",
    "        X=numpy.zeros(shape=(1,500*32))\n",
    "        Y=numpy.zeros(shape=(1,))\n",
    "        count=-1\n",
    "        for f in files:\n",
    "             if not (f.startswith('.')):\n",
    "                folder = os.path.join(path, f)\n",
    "                filenames = os.listdir(folder)\n",
    "                count+=1\n",
    "                for fi in filenames:\n",
    "                    if not (fi.startswith('.')):\n",
    "                        filepath = os.path.join(folder, fi)\n",
    "                        #print filepath\n",
    "                        image = cv2.imread(filepath, 0)\n",
    "                        kp, features = orb.detectAndCompute(image,None)\n",
    "                        #print features.shape\n",
    "                        features=features.reshape(1,500*32)\n",
    "                        #print features.shape\n",
    "                        X = numpy.vstack((X, features))\n",
    "                        Y=numpy.vstack((Y,numpy.asarray([count])))\n",
    "        #print X.shape\n",
    "        Y=Y.reshape(Y.shape[0],)\n",
    "        return X,Y\n",
    "\n",
    "    def model_svm(self,X,y):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        C_score = []\n",
    "        grid = np.arange(0.01, 3, 0.1)\n",
    "        for K in grid:\n",
    "            clf = SVC(C=K)\n",
    "            # Calculate the mean scores for each value of hyperparameter C\n",
    "            scores = cross_val_score(clf, X_train, Y_train, cv=5)\n",
    "\n",
    "            print(scores.mean())\n",
    "            C_score.append(scores.mean())\n",
    "\n",
    "        # Display the maximum score achieved at which hyperparameter value\n",
    "        print (\" max score is \", max(C_score), \" at C = \", grid[C_score.index(max(C_score))])\n",
    "        clf = SVC(C=grid[C_score.index(max(C_score))])\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(\"accuracy is {}\".format(accuracy_score(Y_test, y_pred)))\n",
    "\n",
    "    def model_KNN(self,X,Y):\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "        clf = neighbors.KNeighborsClassifier(10)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(accuracy_score(Y_test, y_pred))\n",
    "\n",
    "    def model_randomforest(self,X,Y):\n",
    "        print (\"printing data shape {}\".format(X.shape))\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "        K=1000\n",
    "        clf = RandomForestClassifier(n_estimators=K)\n",
    "        # Calculate the mean scores for each value of hyperparameter C\n",
    "        #scores = cross_val_score(clf, X, Y, cv=5)\n",
    "        #print scores.mean()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(accuracy_score(Y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m=model()\n",
    "X,Y=m.preprocess_data(\"C:\\\\Users\\\\anany\\\\OneDrive\\\\Documents\\\\IIITD\\\\DPM\\\\Data\")\n",
    "#m.model_svm(X,Y)\n",
    "#m.model_KNN(X,Y)\n",
    "m.model_randomforest(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('C:\\\\Users\\\\anany\\\\OneDrive\\\\Documents\\\\IIITD\\\\DPM\\\\Data\\\\Ancient\\\\04.jpg')\n",
    "image = cv2.imread('C:\\\\Users\\\\anany\\\\Downloads\\\\taj_mahal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 512, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='C:\\\\Users\\\\anany\\\\OneDrive\\\\Documents\\\\IIITD\\\\DPM\\\\Data\\\\Ancient'\n",
    "image_names = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='C:\\\\Users\\\\anany\\\\OneDrive\\\\Documents\\\\IIITD\\\\DPM\\\\Git Project\\\\Templates\\\\Data\\\\Ancient'\n",
    "image_names = os.listdir(path)\n",
    "string = 'Ancient/'\n",
    "full_filename = [string+ x for x in image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ancient/01.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import faiss\n",
    "list = ['Ancient','British','Indo-Islamic','Maratha','Not a Monument', 'Sikh']\n",
    "with open('C:\\\\Users\\\\anany\\\\OneDrive\\\\Documents\\\\IIITD\\\\DPM\\\\images.npy', 'rb') as f:\n",
    "        X= np.load(f)\n",
    "with open('C:\\\\Users\\\\anany\\\\OneDrive\\\\Documents\\\\IIITD\\\\DPM\\\\labels.npy', 'rb') as g:     \n",
    "        Y= np.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "def fitModel(train_features): \n",
    "   index = faiss.IndexFlatL2(train_features.shape[1])   # build the index \n",
    "   index.add(train_features)       # add vectors to the index\n",
    "   return index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= X_test.astype(np.float32)\n",
    "X_train= X_train.astype(np.float32)\n",
    "index= fitModel(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#from collections import Counter\n",
    "from scipy import stats\n",
    "def predict(train_labels, test_features,k): \n",
    "        distance, test_features_faiss_Index = index.search(test_features, k) \n",
    "        test_label_faiss_output = stats.mode(train_labels[test_features_faiss_Index],axis=1)[0]\n",
    "        test_label_faiss_output = np.array(test_label_faiss_output.ravel())\n",
    "        #for test_index in range(0,test_features.shape[0]):\n",
    "        #    self.test_label_faiss_output[test_index] = stats.mode(self.train_labels[test_features_faiss_Index[test_index]])[0][0] #Counter(self.train_labels[test_features_faiss_Index[test_index]]).most_common(1)[0][0] \n",
    "        return test_label_faiss_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(Y_train, X_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(test_label_faiss_output,test_labels):\n",
    "    accuracy = (test_label_faiss_output == test_labels).mean() \n",
    "    return round(accuracy,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path= \"C:\\\\Users\\\\anany\\\\OneDrive\\\\Documents\\\\IIITD\\\\DPM\\\\Data\"\n",
    "files = os.listdir(path)\n",
    "orb = cv2.ORB_create()\n",
    "shape =[]\n",
    "#sift = cv2.xfeatures2d.SIFT_create()\n",
    "X=np.zeros(shape=(1,500*32))\n",
    "Y=np.zeros(shape=(1,))\n",
    "features= np.array([])\n",
    "count=-1\n",
    "for f in files:\n",
    "    if not (f.startswith('.')):\n",
    "        folder = os.path.join(path, f)\n",
    "        filenames = os.listdir(folder)\n",
    "        count+=1\n",
    "    for fi in filenames:\n",
    "        if not (fi.startswith('.')):\n",
    "            filepath = os.path.join(folder, fi)\n",
    "            #print filepath\n",
    "            image = cv2.imread(filepath, 0)\n",
    "            #print(filepath.split('/')[5])\n",
    "            kp, features = orb.detectAndCompute(image,None)\n",
    "            shape = features.shape\n",
    "            if (shape[0]==500 and shape[1]==32):\n",
    "                features=features.reshape(1,500*32)\n",
    "                X = np.vstack((X, features))\n",
    "                Y=np.vstack((Y,np.asarray([count])))\n",
    "            else:\n",
    "                continue\n",
    "Y=Y.reshape(Y.shape[0],)\n",
    "    #print X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(647,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482\n",
      "(322, 32)\n"
     ]
    }
   ],
   "source": [
    "count =0\n",
    "for i in range(len(shape)):\n",
    "    if (shape[i][0]==500 and shape[i][1]==32):\n",
    "       count = count\n",
    "    else:\n",
    "        print(i)\n",
    "        print(shape[i])\n",
    "        count = count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
